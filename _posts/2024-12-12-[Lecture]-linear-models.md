---
categories:
- Studies
date: '2024-12-12'
tags:
- Lecture
- model
title: '[Lecture] Linear Models'
toc: true
---


# Linear Regression; ì„ í˜• íšŒê·€

> ğŸ¦œ **Linear Model; ì„ í˜• ëª¨ë¸**\
ë…ë¦½ë³€ìˆ˜ $$x$$ë¡œ ì¢…ì†ë³€ìˆ˜ $$y$$ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸
â†’ ì†ì„±ë“¤ì˜ ì„ í˜• ì¡°í•©ì„ í†µí•´ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜ë¥¼ í•™ìŠµí•˜ëŠ” ëª¨ë¸


### $$f(x) = \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_d x_d + b$$

- Parameter; íŒŒë¼ë¯¸í„°
    - í•™ìŠµì„ í†µí•´ ì–»ì–´ì•¼ í•˜ëŠ” ê°’
    - $$\beta, b$$
**â†’ **$$f(x) = \beta^T x + b$$** (ë²¡í„° í˜•íƒœ)**


# ì„ í˜•íšŒê·€ì˜ ì†ì‹¤í•¨ìˆ˜ (Loss function)

> MSE, Mean Squared Error; í‰ê·  ì œê³± ì˜¤ì°¨

$$MSE = \frac{1}{m} \sum_{i=1}^m (f(x_i) - y_i)^2 = \frac{1}{m} \sum_{i=1}^m (y_i - (b + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_d x_{id}))^2$$

- Input featureê°€ í•˜ë‚˜ ë¿ì¸ ê²½ìš°
    - $f(x_i) = \beta x_i + b$
    - $MSE = \frac{1}{m} \sum_{i=1}^m (y_i - (\beta x_i + b))^2$

## Least Square Method; ìµœì†Œì œê³±ë²•

$$\beta, b$$ë¥¼ ì°¾ëŠ” ê²ƒì€ $$E_{(\beta, b)} = \sum_{i=1}^m (y_i - \beta x_i - b)^2$$ë¥¼ ìµœì†Œí™” í•˜ëŠ” ê³¼ì •ì´ë‹¤.

![](/assets/images/lecture-linear_models/image_20241212_045756_1b468c15130f4aabafb0d5eb3f0a140d.png)

ì´ë¯€ë¡œ

![](/assets/images/lecture-linear_models/image_20241212_045758_7c41103b25474299b56337364fa3f832.png)

ì´ë‹¤.


## Multivariate Linear Regression

> Featureê°€ ì—¬ëŸ¬ ê°œë¼ë©´ í–‰ë ¬ í˜•íƒœë¡œ í‘œí˜„í•œë‹¤.

![](/assets/images/lecture-linear_models/image_20241212_045758_2e8bf034a74c411c98e4564e0e2af1fb.png)


