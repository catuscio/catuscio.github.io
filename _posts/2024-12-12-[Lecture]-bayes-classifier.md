---
categories:
- Studies
date: '2024-12-12'
tags:
- Lecture
- Bayes
- ë² ì´ì¦ˆ
- í™•ë¥ 
title: '[Lecture] Bayes Classifier'
toc: true
---


## Topology

- **ì¡°ê±´ë¶€ í™•ë¥  $$P(A \vert B)$$ :** Bë¼ê³  í–ˆì„ ë•Œ Cì¼ í™•ë¥ 
- **ì£¼ë³€ í™•ë¥  (Marginal probability) $$P(x)$$:** $$x$$ ìì²´ì˜ ë¶„í¬.
- **ì‚¬ì „ í™•ë¥  (Prior probability) $$P(c)$$ :** ì‚¬ì „ì— ì•Œê³  ìˆëŠ” í™•ë¥ . $$c$$ëŠ” ì¶”ì •í•˜ê³ ì í•˜ëŠ” ê°’.
- **ì‚¬í›„ í™•ë¥  (Posterior probability) $$P(c \vert x)$$ :** $$x$$ë¥¼ $$c$$ë¡œ ë¶„ë¥˜í–ˆì„ ë•Œ ë§ì•˜ì„ í™•ë¥ 
- **ì†ì‹¤ (Loss) $$\lambda_{ij}$$ :** $$c_j$$ì¸ $$x$$ë¥¼ $$c_i$$ë¡œ ë¶„ë¥˜í–ˆì„ ë•Œì˜ ì†ì‹¤. 0 or 1
- **ê¸°ëŒ€ ì†ì‹¤ (Expected loss) $$R(c \vert x)$$ :** $$x$$ë¥¼ $$c$$ë¡œ ë¶„ë¥˜í–ˆì„ ë•Œ í‹€ë ¸ì„ í™•ë¥ 
- **ìš°ë„ (Likelihood) $$P(x \vert c)$$ :** $$x$$ì˜ ë¶„ë¥˜ê°€ $$c$$ì¼ í™•ë¥ 

# Bayesian Decision Theory


## **ë‹¤ì¤‘ ë¶„ë¥˜ ì˜ˆì‹œ (multi-class classification)**

> **ëª©í‘œ : ê¸°ëŒ€ ì†ì‹¤ $$R(c \vert x)$$ ìµœì†Œí™”**


### ì •ì˜

- $$N$$ê°œì˜ ë¶„ë¥˜ ë ˆì´ë¸” $$Y=\{ c_1, c_2, \cdots, c_N \}$$ì´ ìˆê³ , **ì‚¬í›„ í™•ë¥  (Posterior probability) **$$P(c_i  \vert  x)$$ì— ê¸°ë°˜í•˜ì—¬ **ìƒ˜í”Œ **$$x$$**ë¥¼ **$$c_i$$**ë¡œ ë¶„ë¥˜**í–ˆì„ ë•Œ ë°œìƒí•˜ëŠ” ê¸°ëŒ€ ì†ì‹¤ (expected loss)ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.
- ì´ ë•Œ $$\lambda_{ij}$$ëŠ” ì‹¤ì œ ë ˆì´ë¸”ì´ $$c_j$$ì¸ ìƒ˜í”Œì´ $$c_i$$ë¡œ ì˜ëª» ë¶„ë¥˜í–ˆì„ ë•Œ ë°œìƒí•˜ëŠ” ì†ì‹¤
    - $$R(c_i  \vert  x) = \sum_{j=1}^N \lambda_{ij} P(c_j \vert x)$$
    - $$x$$ë¥¼ $$c_i$$ë¡œ ë¶„ë¥˜í–ˆì„ ë•Œ ê¸°ëŒ€ ì†ì‹¤(expected loss)
= (ì‹¤ì œë¡œëŠ” $$c_j$$ì¸ ë°ì´í„°ì˜ ì†ì‹¤) $$\times$$ (ì‚¬í›„ í™•ë¥ )

- íŒë³„ ê¸°ì¤€ $$h:Xâ†’Y$$ë¥¼ ì°¾ì•„ ì „ì²´ ì†ì‹¤ì„ ìµœì†Œí™”í•´ì•¼ í•œë‹¤.
    - $R(h)=\mathbb{E}_x[R(h(x)) \vert x)]$
> ğŸ”´ $$x$$ë¥¼ $$c_i$$ë¡œ ë¶„ë¥˜í–ˆì„ ë•Œ **ê¸°ëŒ€ ì†ì‹¤(expected loss)**


### í•´ê²°

- ê° ìƒ˜í”Œ $$x$$ì— ëŒ€í•´ ì†ì‹¤ $$R(h(x) \vert x)$$ ìµœì†Œí™” â†’ ì „ì²´ ë¦¬ìŠ¤í¬ ìµœì†Œí™”
- **ë² ì´ì¦ˆ ê²°ì • ê·œì¹™**
    - ê° ìƒ˜í”Œì— ëŒ€í•˜ì—¬ $$R(c \vert x)$$ë¥¼ ìµœì†Œí™”í•˜ëŠ” í´ë˜ìŠ¤ ë ˆì´ë¸” ì„ íƒ
        - $h^*(x) = \mathrm{argmin}_{c \in Y} R(c \vert x)$
    - $$h^*$$<u>ëŠ” ë² ì´ì¦ˆ ìµœì  ë¶„ë¥˜ê¸° (Bayes Optimal Classifer)!</u>
- ë§Œì•½ ëª©í‘œê°€ ë¶„ë¥˜ê¸°ì˜ ì˜¤ì°¨ìœ¨ (misclassification rate)ì„ ìµœì†Œí™” í•˜ëŠ” ê²ƒì´ë¼ë©´
    - $\lambda_{ij} = \begin{cases} 0, & \text{if } i = j \\ 1, & \text{otherwise} \end{cases}$
    - $$R(c_i  \vert  x) = 1 - P(c_i  \vert  x)$$ (conditionl risk) ì´ë¯€ë¡œ
    - $$h^*(x) = \mathrm{argmax}_{c \in Y} P(c \vert x)$$ â†’ (Rì„ Pë¡œ ë°”ê¿ˆ)
- <u>ê° ìƒ˜í”Œ </u>$$x$$<u>ì— ëŒ€í•´ ì‚¬í›„ í™•ë¥  </u>$$P(c \vert x)$$<u>ë¥¼ ìµœëŒ€í™” í•  ìˆ˜ ìˆëŠ” í´ë˜ìŠ¤ ë ˆì´ë¸”ì„ ì„ íƒ!</u>
> ğŸ”´ 1. ì „ì²´ ì†ì‹¤ $$R(h)=\mathbb{E}_x[R(h(x)) \vert x)]$$ë¥¼ ìµœì†Œí™” í•´ì•¼ í•˜ë¯€ë¡œ
ê° ìƒ˜í”Œì— ëŒ€í•œ ì†ì‹¤ $$R(h(x) \vert x)$$ì„ ìµœì†Œí™” í•œë‹¤.

2. ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´ $$h^*(x) = \mathrm{argmin}_{c \in Y} R(c \vert x)$$

3. R = 1 - P ì´ë¯€ë¡œ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œëŠ” $$h^*(x) = \mathrm{argmax}_{c \in Y} P(c \vert x)$$


## ë² ì´ì¦ˆ ì •ë¦¬ (Bayes Theorem)

> **ëª©í‘œ : ì‚¬í›„ í™•ë¥  $$P(c \vert x)$$ ë„ì¶œ**

$$P(c \vert x) = \frac{P(c)P(x \vert c)}{P(x)}$$

(ì‚¬í›„ í™•ë¥ ) = (ì‚¬ì „ í™•ë¥ ) $$\times$$(ìš°ë„) $$\div$$ (ì£¼ë³€ í™•ë¥ )

- Marginal probability $$P(x)$$ëŠ” ìƒìˆ˜
- Prior probability $$P(c)$$ëŠ” ì¶œí˜„ ë¹ˆë„ë¥¼ í†µí•´ ê³„ì‚° ê°€ëŠ¥
- LikelihoodëŠ” ì–´ì¼€ êµ¬í•¨?

# ìµœëŒ€ ìš°ë„ ì¸¡ì •; Maximum Likelihood Estimation

ìš°ë„ê°€ ì •í•´ì§„ í˜•ì‹ì´ ìˆê³ , íŒŒë¼ë¯¸í„° $$\theta_c$$ì— ì˜í•´ì„œë§Œ ê²°ì •ë¨

$$D_c$$ë¡œ í›ˆë ¨ì„¸íŠ¸ $$D$$ì—ì„œ $$c$$í´ë˜ìŠ¤ ìƒ˜í”Œë¡œ êµ¬ì„±ëœ ì§‘í•©ì„ ë‚˜íƒ€ë‚´ê³ , ì´ëŸ° ìƒ˜í”Œë“¤ì´ ë…ë¦½í•­ë“±ë¶„í¬(iid)ë¼ê³  ê°€ì •í–ˆì„ ë•Œ, ë°ì´í„°ì„¸íŠ¸ $$D_c$$ì— ëŒ€í•œ íŒŒë¼ë¯¸í„° $$\theta_c$$ì˜ ìš°ë„ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

$$P(D_c \vert \theta_c) = \prod_{x \in D_c} P(x \vert \theta_c)$$

ê³±ì…ˆì„ í”¼í•´ ë¡œê·¸ ìš°ë„ë¥¼ ì‚¬ìš©í•˜ë©´

$$LL(\theta_c)=\log P(D_c \vert \theta_c) = \sum_{x \in D_c} \log P(x \vert \theta_c)$$


## MLE; Maximum Likelihood Estimation

![](/assets/images/lecture-bayes_classifier/image_20241212_051024_f65caaf05cf0401f8c25f21cc0bba451.png)

ë™ì „ ë˜ì§€ê¸° : $$D = (x_1, x_2, \cdots, x_7) = (H, H, T, T, H, H, H)$$

ê° ìƒ˜í”Œë“¤ì´ ì•„ë˜ì˜ ë² ë¥´ëˆ„ì´ ë¶„í¬ë¥¼ ë”°ë¥´ë©°, ë…ë¦½ì ì´ë¼ê³  í•œë‹¤ë©´ MLEë¡œ ì¶”ì •í•œ $$\theta$$ëŠ”?

$$P(x \vert \theta) = \begin{cases} \theta & x = H \\ 1-\theta & \text{if } x=T \end{cases}$$

**sol**

$\text{Likelihood} = \theta^5(1-\theta)^2$

ì„ maximize í•˜ëŠ” $$\theta$$ë¥¼ êµ¬í•˜ì.

$LL = 5\ln\theta + 2\ln(1-\theta)$

ì–‘ ë³€ì— ìŒìˆ˜ ì·¨í•˜ë©´

$-LL = -5\ln\theta - 2\ln(1-\theta)$

LLì´ 0ì´ ë˜ë„ë¡ í•˜ëŠ” $$\theta$$ ê°’ì€

$-\frac{5}{\theta} + \frac{2}{1-\theta} =0$

ì–‘ë³€ì— $$\theta(1-\theta)$$ë¥¼ ê³±í•˜ë©´

$\theta = \frac{5}{7}$


### MLEì˜ í•œê³„

- ì¶”ì • ê²°ê³¼ì˜ ì •í™•ì„±ì´ **ê°€ì •í•˜ëŠ” í™•ë¥  ë¶„í¬ í˜•ì‹ì´ ì ì¬ì ì¸ ì‹¤ì œ ë°ì´í„° ë¶„í¬ì™€ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ì— ê³¼í•˜ê²Œ ì˜ì¡´**í•œë‹¤.
- ì´ìƒí•œ í™•ë¥  ë¶„í¬ ì“°ë©´ ì¢†ë  ìˆ˜ ìˆë‹¤!

# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸°; Naive Bayes Classifier

íŒŒë¼ë¯¸í„°í™” ì—†ì´ (== ë¶„í¬ ê°€ì • ì—†ì´) ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ì—†ì„ê¹Œ?

ë¬¸ì œëŠ” ìš°ë„ê°€ **ëª¨ë“  ì†ì„±(feature)ì— ëŒ€í•œ ê²°í•© í™•ë¥ **ì´ê¸° ë•Œë¬¸ì— ìœ í•œí•œ í›ˆë ¨ ìƒ˜í”Œë§Œìœ¼ë¡œëŠ” ì¶”ì •ì´ ì–´ë µë‹¤.

ë”°ë¼ì„œ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸°ëŠ” **ì†ì„± ì¡°ê±´ë…ë¦½ ê°€ì„¤ (Attribute Conditional Independence Assumption)ì„ ì´ìš©í•œë‹¤.**

ì´ê±´ ê± ê³¼ì œ ë´ë¼~~



## ê³„ì‚° ë°©ë²•

- Prior
ì „ì²´ ë°ì´í„° Dì— ëŒ€í•´ c í´ë˜ìŠ¤ ìƒ˜í”Œë¡œ êµ¬ì„±ëœ ì§‘í•©ì„ D_cë¼ê³  í•˜ë©´, í´ë˜ìŠ¤ priorëŠ”

$P(c) = \frac{ \vert D_c \vert }{ \vert D \vert }$

- Likelihood
$$D_{c,x_i}$$ë¥¼ $$D_c$$ ì¤‘ì— ì†ì„± iìƒì—ì„œì˜ ê°’ì´ $$x_i$$ì¸ ìƒ˜í”Œë¡œ êµ¬ì„±ëœ ì§‘í•©ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ë‹¤ë©´, ì†ì„±ë³„ ìš°ë„ $$P(x_i \vert c)$$ëŠ”

$$P(x_i \vert c) = \frac{ \vert D_{c,x_i} \vert }{ \vert D_c \vert }$$

$$= \frac{1}{\sqrt{2\pi}\sigma_{c,i}} \exp (-\frac{(x_i - \mu_{c,i})^2}{2\sigma_{c,i}^2})$$


## ë¼í”Œë¼ì‹œì•ˆ ë³´ì • (Laplacian Correction)

í•´ë‹¹ ì»¬ëŸ¼ì˜ í´ë˜ìŠ¤ ê°œìˆ˜ë¥¼ Nì´ë¼ í•˜ì.

![](/assets/images/lecture-bayes_classifier/image_20241212_051026_8adf0c8a1d61437ea9be66f005b6cd4b.png)

$\ln{(2\pi\sigma_c^2)^{-\frac{n}{2}}}$


