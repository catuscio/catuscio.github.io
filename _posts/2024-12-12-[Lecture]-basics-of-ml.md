---
categories:
- Studies
date: '2024-12-12'
tags:
- Lecture
- ML
title: '[Lecture] Basics of ML'
toc: true
---


## ë¨¸ì‹ ëŸ¬ë‹ì´ë€?

ë°ì´í„°ë¡œë¶€í„° ê·œì¹™ì„ í•™ìŠµí•˜ëŠ” í”„ë¡œê·¸ë˜ë° (í˜¹ì€ íŒ¨í„´ ì¸ì‹)


## ì§€ë„/êµì‚¬ í•™ìŠµ(Supervised Learning)

- ë°ì´í„°ì™€ ì •ë‹µì„ í•¨ê»˜ ì œê³µí•˜ì—¬ í•™ìŠµí•˜ê²Œ í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
    - Regression(íšŒê·€) â†’ ì—°ì†ì ì¸ ê°’ ì˜ˆì¸¡(Continuous)
    - Classification(ë¶„ë¥˜) â†’ ì´ì‚°ì ì¸ ê°’ ì˜ˆì¸¡(Discrete)
![](/assets/images/lecture-basics_of_ml/image_20241212_043905_3ed9b15fa80842e0a6c4206cdfcdcaba.png)


### ì§€ë„í•™ìŠµì˜ ëª©í‘œ

> ê°€ì¥ ì´ìƒì ì¸ ëª¨ë¸(Ideal model) $$F$$ì„ ê·¼ì‚¬í•  ìˆ˜ ìˆëŠ” í˜„ì‹¤ ëª¨ë¸(Real model) $$f$$ë¥¼ ë§Œë“œëŠ” ê²ƒ\
â†’ ì‹¤ì œ ì¶œë ¥ê°’ $$y$$ì™€ ì˜ˆì¸¡ê°’ $$\hat y$$ë¥¼ ë¹„ìŠ·í•˜ë„ë¡ $$f$$ë¥¼ í•™ìŠµí•˜ì\
â†’ $$y$$ì™€ $$\hat y$$ì˜ ì°¨ì´ $$\Delta$$ë¥¼ ì¤„ì´ì.


### ì°¨ì´(Loss)ë¥¼ ì •ì˜í•˜ëŠ” ë°©ë²•

ì ˆëŒ“ê°’ $$\lVert y-\hat y \rVert $$ ê³¼ ì œê³±ê°’ $$(y-\hat y)^2$$

> **ì†ì‹¤í•¨ìˆ˜(**$$L$$**, Loss Function)**
- ìµœì í™” ë¬¸ì œì—ì„œëŠ” ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™” í•˜ê³ ì í•¨. ì–´ë–¤ í•™ìŠµì˜ â€˜ë¹„ìš©â€™

### $$L$$, Loss Function

> ğŸ¥¬ í‰ê·  ì œê³± ì˜¤ì°¨(MSE, Mean Squared Error)\
$$L = \frac{1}{n} \sum_{i=1}^n(\hat y_i - y_i)^2$$

Lossë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©ë²•ì—ëŠ” ë‹¤ìŒì´ ìˆë‹¤.

- **ë‹«íŒ í•´(Closed-form solution)**
    - ë°ì´í„°ì™€ ì†ì‹¤ í•¨ìˆ˜ê°€ ì£¼ì–´ì§€ë©´ ìµœì ì˜ ëª¨ë¸ì´ ê³„ì‚°ì„ í†µí•´ ë„ì¶œë˜ëŠ” ê²ƒ
    - e.g. ì •ê·œë°©ì •ì‹(Normal Equation)
- **ê·œì¹™ ê¸°ë°˜ ìµœì í™”(Rule-based optimization)**
    - ì‚¬ì „ì— ì§€ì •ëœ ê·œì¹™ì„ í†µí•´ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì¤„ì—¬ ë‚˜ê°€ëŠ” ê²ƒ
    - e.g. ì˜ì‚¬ê²°ì •ë‚˜ë¬´(Decision Tree)
- **ê²½ì‚¬í•˜ê°•ë²•(Gradient Descent)**
    - ë°˜ë³µí•´ì„œ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ ì›€ì§ì´ëŠ” ê²ƒ

### Over/Underfitting

<div class='column-list' style='display: flex; gap: 1em;'>
<div class='column' style='flex: 1; padding: 0.5em; background-color: #f9f9f9; border: 1px solid #ddd; border-radius: 5px;'>
![](/assets/images/lecture-basics_of_ml/image_20241212_043908_0acfc2d8a78843a09134f6a93839ee4e.png)

</div>
<div class='column' style='flex: 1; padding: 0.5em; background-color: #f9f9f9; border: 1px solid #ddd; border-radius: 5px;'>
í¸í–¥(Bias)ê³¼ ë¶„ì‚°(Variance)


![](/assets/images/lecture-basics_of_ml/image_20241212_043910_f2534cf84188412e9ed2a08c64ba4e35.png)

ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ Train/Test splitì„ í•œë‹¤.



</div>
</div>


### ì§€ë„í•™ìŠµì˜ ì „ê°œ

<div class='column-list' style='display: flex; gap: 1em;'>
<div class='column' style='flex: 1; padding: 0.5em; background-color: #f9f9f9; border: 1px solid #ddd; border-radius: 5px;'>
![](/assets/images/lecture-basics_of_ml/image_20241212_043912_06298eb8b3c94d4295530ddfc3cc7447.png)

</div>
<div class='column' style='flex: 1; padding: 0.5em; background-color: #f9f9f9; border: 1px solid #ddd; border-radius: 5px;'>
        1. ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„/ì „ì²˜ë¦¬
        1. Train/Test setìœ¼ë¡œ ë°ì´í„° ë¶„í• 
        1. ëª¨ë¸ í›„ë³´êµ° ì„¤ì •
        1. ì†ì‹¤ í•¨ìˆ˜ ë° íƒìƒ‰ ë°©ë²• ì„¤ì •
        1. Training Setì„ í†µí•œ ëª¨ë¸ í•™ìŠµ
            1. í•„ìš”ì‹œ Validation setìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        1. Test setì„ í†µí•œ ì„±ëŠ¥/ê³¼ì í•© í™•ì¸
        1. (1-6) ë°˜ë³µ
</div>
</div>


## ë¹„ì§€ë„/ë¹„êµì‚¬ í•™ìŠµ(Unsupervised Learning)

- ë°ì´í„°ë§Œì„ ì œê³µí•˜ì—¬ í•™ìŠµí•˜ê²Œ í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜
    - Clustering
    - Recommendation System
![](/assets/images/lecture-basics_of_ml/image_20241212_043915_43ab70ef1d574cffb9d68d3711dda246.png)

