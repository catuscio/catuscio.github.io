---
categories:
- Studies
date: '2024-12-12'
tags:
- LG Aimers
title: '[LG Aimers] Gradient Descent'
toc: true
---


# Overview

- We have some function (loss function)
    - $J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2$
- and want
    - $\min_{\theta_0, \theta_1}J(\theta_0, \theta_1)$
- Algorithm outline
    - Start with some initial parameters $$\theta_0, \theta_1$$
    - Keep changing the parameter to reduce the loss function until we hopefully end up at a minimum.
> ðŸ’¡ repeat until convergence { \
$\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j}J(\theta_0, \theta_1)$ \
}

- **Gradient**: partial derivative of vector function
    - Direction of greatest increase (or decrease) of a function
- **Step size **$$\alpha$$: affects rate of the downside movement of the vector on error surface
    - Must be a positive number
    - **Hyper parameter**
    - If its too small, GD can be slow; if its too large, GD can overshoot the minimum and fail to converge (or diverge)
- $$\theta$$: **Learnable parameters**
- **Objective function **$$J$$: What we have to minimize
![](/assets/images/lg_aimers-gradient_descent/image_20241212_040434_6b7624ced73c4a6297784c0be242c82b.png)


# Batch gradient descent

> ðŸ’¡ repeat until convergence {\
    $\theta_0 := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})$ \
    $\theta_1 := \theta_1 - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})\cdot x^{(i)}$ \
}

Linear regression model

$$h_\theta(x) = \theta_0 + \theta_1 x$$

$$J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2$$

- ì„ í˜•íšŒê·€ ëª¨ë¸ì—ì„œ ëª©ì í•¨ìˆ˜ $$J$$ì˜ íŽ¸ë¯¸ë¶„ì„ ì‚½ìž…í•˜ì—¬ $$\theta_0, \theta_1$$ì„ ë°”ê¿ˆ.
- Sample size $$m$$ì´ ë„ˆë¬´ ì»¤ì§€ë©´ ê³„ì‚° ë³µìž¡ë„ê°€ ëŠ˜ì–´ë‚¨.

# Stochastic gradient descent (SGD)

> ðŸ’¡ repeat until convergence { \
$\theta_0 := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})$ \
$\theta_1 := \theta_1 - \alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})\cdot x^{(i)}$ \
}

- SGDëŠ” $$m=1$$ë¡œ ê³„ì‚°í•œë‹¤.
- Batch GDì— ë¹„í•´ ë¹ ë¥´ì§€ë§Œ, ê° ìƒ˜í”Œ í•˜ë‚˜í•˜ë‚˜ë§ˆë‹¤ ê³„ì‚°í•˜ë¯€ë¡œ ë…¸ì´ì¦ˆì— ì·¨ì•½í•˜ë‹¤. (oscillation occur)

# Limitation : Local Optimum

$$\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j}J(\theta_0, \theta_1)$$

![](/assets/images/lg_aimers-gradient_descent/image_20241212_040435_81415798a20c48998c1d2d1f5fd78434.png)

>*GD algorithmì˜ ì‹œìž‘ ìœ„ì¹˜ì— ë”°ë¼ local minimumê³¼ global minimum ì¤‘ í•˜ë‚˜ê°€ ë°œìƒí•˜ê²Œ ë˜ëŠ” ì˜¤ë¥˜ê°€ ìžˆë‹¤.*

- Critical points with zero slope: $$\nabla_xf(x)=0$$ gives no information about which direction to move
    - Gradientê°€ 0ì´ ë˜ì–´ ë” ì´ìƒ ìž‘ë™í•˜ì§€ ì•Šê³„ ë˜ëŠ” ë¬¸ì œì .

# Ideas to avoid local minimum


## Momentum

ê³¼ê±°ì— Gradientê°€ ì—…ë°ì´íŠ¸ ë˜ì–´ì˜¤ë˜ ë°©í–¥ ë° ì†ë„ë¥¼ ì–´ëŠ ì •ë„ ë°˜ì˜í•´ì„œ í˜„ìž¬ í¬ì¸íŠ¸ì—ì„œ Gradientê°€ 0ì´ ë˜ë”ë¼ë„ ê³„ì†í•´ì„œ í•™ìŠµì„ ì§„í–‰í•  ìˆ˜ ìžˆëŠ” ë™ë ¥ì„ ì œê³µí•˜ê²Œ ë˜ëŠ” ê²ƒ

- SGD: widely used but slow and difficult to reach the minimum
- Momentum
    - speed up learnining in high curvature and small/noise gradient
    - Exponentially weighted moving average of past gradients (low pass filtering)
> ðŸ’¡ 
    $$v_t = \begin{cases} g_1, & t = 1\\ \rho v_{t-1} + (1-\rho)g_t, & t>1 \end{cases}$$
    > - $$v_t$$ : Momentum. Exponentially weighted moving average at time $$t$$
    > - $$g_t$$ : observation gradient at time $$t$$
    > - $$\rho$$ (0~1) : degree of weighting decrease (smoothing factor)

c.f) recursive equation â†’ exponentially weighted average moving

$$v_t = \rho^k v_{t-k} + (1-\rho)[g_t + \rho g_{t-1} + \cdots + \rho^{k-1} g_{t-k+1}]$$


